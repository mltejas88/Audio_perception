{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3883d4b",
   "metadata": {},
   "source": [
    "Whisper is a speech-to-text system developed by OpenAI. It's a powerful, open-source neural network model trained to convert spoken language into written text — essentially transcription."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fa517a",
   "metadata": {},
   "source": [
    "1) This defines a function called transcribe, which takes one argument:\n",
    "audio_path: the file path to an audio file (e.g., 'command.wav', 'speech.mp3', etc.)\n",
    "\n",
    "2) This line tells the model to transcribe the audio file.\n",
    "Whisper internally:\n",
    "Loads the audio, Converts it to text, Also detects language and timestamps (if needed)\n",
    "\n",
    "3) From the returned result dictionary, it returns only the transcribed text.\n",
    "The full result object also includes:\n",
    "'language': detected spoken language, 'segments': timestamps and partial results, 'text': the full transcription (this is what we return here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fb3f659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 139M/139M [00:13<00:00, 10.6MiB/s]\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"base\")  # Use \"small\" or \"medium\" for better results\n",
    "\n",
    "def transcribe(audio_path):\n",
    "    result = model.transcribe(audio_path)\n",
    "    return result['text']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
